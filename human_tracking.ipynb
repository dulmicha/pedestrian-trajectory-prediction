{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import subprocess\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjustment to our task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_from_file(video_name=\"20231109-112058_10s.mp4\", input_path=\"data/videos\", output_path=\"data/extracted\"):\n",
    "    model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "    rows = []\n",
    "    cap = cv2.VideoCapture(input_path + \"/\" + video_name)\n",
    "\n",
    "    for i, (_, boxes, track_ids, _) in enumerate(track(model, cap)):\n",
    "        for box, track_id in zip(boxes, track_ids):\n",
    "            x, y, w, h = box\n",
    "            rows.append([i, track_id, x.item(), y.item()])\n",
    "    pd.DataFrame(rows, columns=[\"frame\", \"track_id\", \"x\", \"y\"], index=None).to_csv(\n",
    "        output_path + \"/\" + video_name.replace(\".mp4\", \".csv\"), index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(input_path=\"data/videos\", output_path=\"data/extracted\"):\n",
    "\n",
    "    video_names = os.listdir(input_path)\n",
    "    not_processed = []\n",
    "\n",
    "    for video_name in video_names:\n",
    "        try:\n",
    "            extract_data_from_file(video_name=video_name, input_path=input_path, output_path=output_path)\n",
    "        except Exception as e:\n",
    "            not_processed.append(video_name)\n",
    "\n",
    "    return not_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistanceConverter:\n",
    "    \n",
    "    @staticmethod\n",
    "    def pixels2meters(x, y):\n",
    "        X_px2meters = lambda x, y: (1 - ((1.47*y + 161.76 - x) / (1.47*y + 161.76))) * 8\n",
    "        Y_px2meters = lambda y: 6.16793058e-07*y**3 -8.61522438e-04*y**2 + 4.31688489e-01*y -4.75010213e+01   \n",
    "        return X_px2meters(x, y), Y_px2meters(y)\n",
    "    \n",
    "    @staticmethod\n",
    "    def meters2pixels(x, y):\n",
    "        X_meters2px = lambda x, y: (1.47*y + 161.76) * x/8\n",
    "        Y_meters2px = lambda y: 1.51690315e-02*y**3 -3.20503299e-01*y**2 + 7.27107405e+00*y+ 1.47945378e+02\n",
    "        y_px = Y_meters2px(y)\n",
    "        return X_meters2px(x, y_px), y_px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_velocity(positions, time, fps):\n",
    "    dt = np.diff(time) * fps\n",
    "    velocity = np.linalg.norm(np.diff(positions)) / dt\n",
    "    # return smooth_data(velocity)\n",
    "    return velocity\n",
    "\n",
    "\n",
    "def smooth_data(data, window_size=3):\n",
    "    return np.concatenate((data[:-1], np.mean(data[-window_size:]) * np.ones(1))) if data[-1] > data[-2]/2 else data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track(model, cap):\n",
    "    # Store the track history\n",
    "    track_history = defaultdict(lambda: [])\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    # Store the detected frames indices and speeds\n",
    "    frames_list = defaultdict(lambda: [])\n",
    "    speeds = defaultdict(lambda: [])\n",
    "\n",
    "    # Loop through the video frames\n",
    "    while cap.isOpened():\n",
    "        # Read a frame from the video\n",
    "        success, frame = cap.read()\n",
    "\n",
    "        if success:\n",
    "            # Run YOLOv8 tracking on the frame, persisting tracks between frames\n",
    "            results = model.track(frame, persist=True, classes=[0], verbose=False)\n",
    "\n",
    "            # Get the boxes and track IDs\n",
    "            boxes = results[0].boxes.xywh.cpu()\n",
    "            track_ids = results[0].boxes.id.int().cpu().tolist()\n",
    "\n",
    "            # Visualize the results on the frame\n",
    "            annotated_frame = results[0].plot(conf=False)\n",
    "\n",
    "            # Plot the tracks\n",
    "            for box, track_id in zip(boxes, track_ids):\n",
    "                x, y, w, h = box\n",
    "                track = track_history[track_id]\n",
    "                track.append((float(x), float(y)))  # x, y center point\n",
    "                if len(track) > 120:  # retain 90 tracks for 90 frames\n",
    "                    track.pop(0)\n",
    "\n",
    "                frames = frames_list[track_id] # indices of frames in which the object was detected\n",
    "                frames.append(cap.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "                if len(frames) > 3:\n",
    "                    frames.pop(0)\n",
    "\n",
    "                # Calculate the speed\n",
    "                if len(track) > 2:\n",
    "                    speed = calculate_velocity(np.array(track)[-3:], np.array(frames), fps)[-1]\n",
    "                    speeds[track_id] = speed\n",
    "\n",
    "                    # Draw the speed in box title\n",
    "                    # cv2.putText(annotated_frame, f\"{speed:.2f} px/s\", (int(x), int(y) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                    #             (255, 255, 255), 1)                    \n",
    "                \n",
    "                x_meters, y_meters = DistanceConverter.pixels2meters(x, y)\n",
    "                cv2.putText(annotated_frame, f\"x={x_meters:.2f}m, y={y_meters:.2f}m\", (int(x), int(y) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                                (255, 255, 255), 1)\n",
    "\n",
    "                # Draw the tracking lines\n",
    "                points = np.hstack(track).astype(np.int32).reshape((-1, 1, 2))\n",
    "                cv2.polylines(annotated_frame, [points], isClosed=False, color=(230, 230, 230), thickness=10)\n",
    "\n",
    "                area = np.array([[[0, 151], [383, 151], [978, 555], [0, 555]]])\n",
    "                alpha = 0.1\n",
    "                overlay = annotated_frame.copy()\n",
    "  \n",
    "                cv2.polylines(overlay, pts = area, isClosed = True, color=(255, 0, 0),thickness=2)\n",
    "                cv2.fillPoly(overlay, area, (255,0,0))\n",
    "                annotated_frame = cv2.addWeighted(overlay, alpha,annotated_frame , 1 - alpha, 0)\n",
    "\n",
    "\n",
    "            yield (annotated_frame, boxes, track_ids, speeds)\n",
    "\n",
    "            # Break the loop if 'q' is pressed\n",
    "            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "        else:\n",
    "            # Break the loop if the end of the video is reached\n",
    "            break\n",
    "\n",
    "    # Release the video capture object and close the display window\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_people_on_plan(people, i):\n",
    "    clear_output(wait=True)\n",
    "    plt.figure(figsize=(7, 10))\n",
    "    plt.title(f\"Second {i // 20}\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.xticks(np.arange(0, 8, 1))\n",
    "    plt.yticks(np.arange(0, 34, 2))\n",
    "    plt.xlim(0, 8)\n",
    "    plt.ylim(34, 0)\n",
    "    for track_id, (x, y) in people.items():\n",
    "        plt.scatter(x, y, label=f\"Person {track_id}\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "video_path = 'data/videos/20231109-113145_30s.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "VIDEO_CODEC = \"MP4V\"\n",
    "\n",
    "output_video_name = \"result.mp4\"\n",
    "tmp_output_path = \"tmp_\" + output_video_name\n",
    "\n",
    "check_conversion = False\n",
    "verbose = False\n",
    "plotting = True\n",
    "\n",
    "output_video = cv2.VideoWriter(\n",
    "    tmp_output_path, cv2.VideoWriter_fourcc(*VIDEO_CODEC), fps, (width, height)\n",
    ")\n",
    "\n",
    "people_at_frame = defaultdict(lambda: defaultdict(lambda: [0, 0]))\n",
    "\n",
    "for i, (frame, boxes, track_ids, speeds) in enumerate(track(model, cap)):\n",
    "    clear_output(wait=True)\n",
    "    cv2.imshow(\"YOLOv8 Tracking\", frame)\n",
    "    # time.sleep(1)\n",
    "\n",
    "    for box, track_id in zip(boxes, track_ids):\n",
    "        x, y, w, h = box\n",
    "        x, y = int(x), int(y)\n",
    "        \n",
    "        if check_conversion:\n",
    "            x_prime, y_prime = DistanceConverter.meters2pixels(*DistanceConverter.pixels2meters(x, y))\n",
    "            area = np.array([[[0, 151], [383, 151], [978, 555], [0, 555]]])\n",
    "            point = np.array([[[x, y]]])\n",
    "            if cv2.pointPolygonTest(area, (x, y), False) > 0:\n",
    "                assert abs(x_prime - x) < x / 20 and abs(y_prime - y) < y / 20, f\"Error in conversion: {x, y} -> {x_prime, y_prime}\"\n",
    "\n",
    "        if verbose:\n",
    "            print(\n",
    "                f\"Person {track_id} is at ({x}, {y}) \"\n",
    "                + (\n",
    "                    f\"commuting at {speeds[track_id]:.2f} px/s\"\n",
    "                    if track_id in speeds\n",
    "                    else \"\"\n",
    "                )\n",
    "            )\n",
    "\n",
    "        people_at_frame[i][track_id] = DistanceConverter.pixels2meters(x, y)\n",
    "\n",
    "    if plotting and i % 10 == 0:\n",
    "        plot_people_on_plan(people_at_frame[i], i)\n",
    "    output_video.write(frame)\n",
    "\n",
    "output_video.release()\n",
    "\n",
    "if os.path.exists(output_video_name):\n",
    "    os.remove(output_video_name)\n",
    "\n",
    "subprocess.run(\n",
    "    [\n",
    "        \"ffmpeg\",\n",
    "        \"-i\",\n",
    "        tmp_output_path,\n",
    "        \"-crf\",\n",
    "        \"18\",\n",
    "        \"-preset\",\n",
    "        \"veryfast\",\n",
    "        \"-hide_banner\",\n",
    "        \"-loglevel\",\n",
    "        \"error\",\n",
    "        \"-vcodec\",\n",
    "        \"libx264\",\n",
    "        output_video_name,\n",
    "    ]\n",
    ")\n",
    "os.remove(tmp_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
