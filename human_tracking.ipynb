{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import subprocess\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pedestrian trajectory tracking and prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Videos obtained from: https://jelenia-gora.webcamera.pl/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_video(record_duration=10):\n",
    "    stream_url = \"https://hoktastream4.webcamera.pl/jeleniagora_cam_73a10c/jeleniagora_cam_73a10c.stream/playlist.m3u8\"\n",
    "\n",
    "    output_file = f\"data/{time.strftime('%Y%m%d-%H%M%S')}_{record_duration}s.mp4\"\n",
    "\n",
    "    ffmpeg_command = [\n",
    "        \"ffmpeg\",\n",
    "        \"-i\",\n",
    "        stream_url,\n",
    "        \"-t\",\n",
    "        str(record_duration),\n",
    "        \"-filter:v\",\n",
    "        \"crop=700:600:350:400\",\n",
    "        output_file,\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        subprocess.run(ffmpeg_command, timeout=record_duration + 10, check=True)\n",
    "    except Exception as e:\n",
    "        os.remove(output_file)\n",
    "        print(e)\n",
    "\n",
    "\n",
    "    print(f\"Recording completed. The video is saved as {output_file}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track(model, cap):\n",
    "    # Store the track history\n",
    "    track_history = defaultdict(lambda: [])\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    # Store the detected frames indices and speeds\n",
    "    frames_list = defaultdict(lambda: [])\n",
    "    speeds = defaultdict(lambda: [])\n",
    "\n",
    "    # Loop through the video frames\n",
    "    while cap.isOpened():\n",
    "        # Read a frame from the video\n",
    "        success, frame = cap.read()\n",
    "\n",
    "        if success:\n",
    "            # Run YOLOv8 tracking on the frame, persisting tracks between frames\n",
    "            results = model.track(frame, persist=True, classes=[0])\n",
    "\n",
    "            # Get the boxes and track IDs\n",
    "            boxes = results[0].boxes.xywh.cpu()\n",
    "            track_ids = results[0].boxes.id.int().cpu().tolist()\n",
    "\n",
    "            # Visualize the results on the frame\n",
    "            annotated_frame = results[0].plot(conf=False)\n",
    "\n",
    "            # Plot the tracks\n",
    "            for box, track_id in zip(boxes, track_ids):\n",
    "                x, y, w, h = box\n",
    "                track = track_history[track_id]\n",
    "                track.append((float(x), float(y)))  # x, y center point\n",
    "                if len(track) > 120:  # retain 90 tracks for 90 frames\n",
    "                    track.pop(0)\n",
    "\n",
    "                frames = frames_list[track_id] # indices of frames in which the object was detected\n",
    "                frames.append(cap.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "                if len(frames) > 2:\n",
    "                    frames.pop(0)\n",
    "\n",
    "                # Calculate the speed\n",
    "                if len(track) > 1:\n",
    "                    speed = np.linalg.norm(np.array(track[-1]) - np.array(track[-2])) * fps / (frames[-1] - frames[-2])\n",
    "                    speeds[track_id] = speed\n",
    "\n",
    "                    # Draw the speed in box title\n",
    "                    cv2.putText(annotated_frame, f\"{speed:.2f} px/s\", (int(x), int(y) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                                (255, 255, 255), 1)\n",
    "\n",
    "                # Draw the tracking lines\n",
    "                points = np.hstack(track).astype(np.int32).reshape((-1, 1, 2))\n",
    "                cv2.polylines(annotated_frame, [points], isClosed=False, color=(230, 230, 230), thickness=10)\n",
    "\n",
    "            yield (annotated_frame, boxes, track_ids, speeds)\n",
    "\n",
    "            # Break the loop if 'q' is pressed\n",
    "            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "        else:\n",
    "            # Break the loop if the end of the video is reached\n",
    "            break\n",
    "\n",
    "    # Release the video capture object and close the display window\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequence_data(sequence_frames, sequence_ids, sequence_x, sequence_y):\n",
    "    data = pd.DataFrame({'Frame': sequence_frames, 'PersonID': sequence_ids, 'X': sequence_x, 'Y': sequence_y})\n",
    "    data.to_csv('sequence.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "video_path = \"data/videos/20231108-190653_10s.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "VIDEO_CODEC = \"MP4V\"\n",
    "\n",
    "output_video_name = \"result.mp4\"\n",
    "tmp_output_path = \"tmp_\" + output_video_name\n",
    "\n",
    "output_video = cv2.VideoWriter(\n",
    "    tmp_output_path, cv2.VideoWriter_fourcc(*VIDEO_CODEC), fps, (width, height)\n",
    ")\n",
    "\n",
    "sequence_frames = []\n",
    "sequence_ids = []\n",
    "sequence_x = []\n",
    "sequence_y = []\n",
    "frame_number = 0\n",
    "\n",
    "for frame_number, (frame, boxes, track_ids, speeds) in enumerate(track(model, cap)):\n",
    "    clear_output(wait=True)\n",
    "    cv2.imshow(\"YOLOv8 Tracking\", frame)\n",
    "    # sleep(1)\n",
    "\n",
    "    for box, track_id in zip(boxes, track_ids):\n",
    "        x, y, w, h = box\n",
    "        x, y = int(x), int(y)\n",
    "\n",
    "        # add data for only one person\n",
    "        if track_id == 4:\n",
    "            sequence_frames.append(frame_number)\n",
    "            sequence_ids.append(track_id)\n",
    "            sequence_x.append(x)\n",
    "            sequence_y.append(y)\n",
    "        print(\n",
    "            f\"Person {track_id} is at ({x}, {y}) \"\n",
    "            + (\n",
    "                f\"commuting at {speeds[track_id]:.2f} px/s\"\n",
    "                if track_id in speeds\n",
    "                else \"\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    frame_number += 1\n",
    "    output_video.write(frame)\n",
    "\n",
    "create_sequence_data(sequence_frames, sequence_ids, sequence_x, sequence_y)\n",
    "output_video.release()\n",
    "\n",
    "if os.path.exists(output_video_name):\n",
    "    os.remove(output_video_name)\n",
    "\n",
    "subprocess.run(\n",
    "    [\n",
    "        \"ffmpeg\",\n",
    "        \"-i\",\n",
    "        tmp_output_path,\n",
    "        \"-crf\",\n",
    "        \"18\",\n",
    "        \"-preset\",\n",
    "        \"veryfast\",\n",
    "        \"-hide_banner\",\n",
    "        \"-loglevel\",\n",
    "        \"error\",\n",
    "        \"-vcodec\",\n",
    "        \"libx264\",\n",
    "        output_video_name,\n",
    "    ]\n",
    ")\n",
    "os.remove(tmp_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trajectory prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('sequence.csv')\n",
    "xy_values = df[['X', 'Y']].to_numpy()\n",
    "\n",
    "def split_sequence(sequence, n_steps):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(len(sequence)):\n",
    "        last_index = i + n_steps\n",
    "\n",
    "        if last_index > len(sequence) - 1:\n",
    "            break\n",
    "\n",
    "        seq_x, seq_y = sequence[i:last_index], sequence[last_index]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "n_steps = 19  \n",
    "\n",
    "train_size = int(0.8 * len(xy_values))\n",
    "\n",
    "X_train, y_train = split_sequence(xy_values[:train_size], n_steps)\n",
    "X_test, y_test = split_sequence(xy_values[train_size:], n_steps)\n",
    "\n",
    "n_features = 2  \n",
    "\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], n_features))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], n_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(layers.LSTM(50, activation='relu', input_shape=(n_steps, n_features)))\n",
    "model.add(layers.Dense(2)) \n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01), loss=tf.keras.losses.MeanSquaredError())\n",
    "\n",
    "model.fit(X_train, y_train, epochs=300, verbose=1)\n",
    "\n",
    "predicted_values = model.predict(X_test, verbose=1)\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    print(f\"Rzeczywiste (X, Y): ({y_test[i][0]}, {y_test[i][1]}), Prognozowane (X, Y): ({predicted_values[i][0]}, {predicted_values[i][1]})\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
